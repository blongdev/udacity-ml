{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries that will be usedin this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the twitter data into a panda dataframe. I originally ran into an encoding issue and had to save the csv in UTF-8. The csv file does not include a column header row, so add those in manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"twitter_data.csv\", header=None, names=[\"sentiment\", \"tweet_id\", \"date\", \"query\", \"user\", \"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment    tweet_id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user  \\\n",
       "0  _TheSpecialOne_   \n",
       "1    scotthamilton   \n",
       "2         mattycus   \n",
       "3          ElleCTF   \n",
       "4           Karoli   \n",
       "\n",
       "                                                                                                                 tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                      my whole body feels itchy and like its on fire   \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that dont seem useful for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                                 tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                      my whole body feels itchy and like its on fire   \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"tweet_id\", \"date\", \"query\", \"user\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT KEEP THIS IN THE PROJECT!!!\n",
    "DROPPING A BUNCH OF ROWS TO SPEED UP PREPROCESSING WHILE TESTING!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(300000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def processTweet(tweet):\n",
    "    tweet = re.sub(\"[@|#]\\w+\\S\",\"\", tweet) # remove @usernames and #hashtags\n",
    "    tweet = re.sub(\"http[s]?://[\\S]+\", '', tweet) # remove urls \n",
    "    tweet = re.sub(r\"(.)\\1\\1+\",r\"\\1\\1\", tweet) # remove letters that repeat more than 2 times\n",
    "    tweet = re.sub('[!&()+,-./:;<=>?[\\\\]_{|}~]', ' ',tweet) # replace certain punctuation with a space \n",
    "    tweet = re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', '',tweet) # remove remaining punctuation\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet) # remove words that are less than 3 characters\n",
    "    tweet = tweet.lower() # lowercase\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1355349</th>\n",
       "      <td>4</td>\n",
       "      <td>just looked  the other stuff  that shop  and the name  persephoneplus  not surprised you like that stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460405</th>\n",
       "      <td>4</td>\n",
       "      <td>the cutest thing ever  two   mice running  their wheel together   wish  had  photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410754</th>\n",
       "      <td>0</td>\n",
       "      <td>with vortex2  bumblebee stayed alive  windshield wiper through golfball size hail  succumbed  highway speeds later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702594</th>\n",
       "      <td>0</td>\n",
       "      <td>nice  and not  nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302007</th>\n",
       "      <td>0</td>\n",
       "      <td>stinky men are sitting beside   the jeep  this sucks  bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment  \\\n",
       "1355349          4   \n",
       "1460405          4   \n",
       "410754           0   \n",
       "702594           0   \n",
       "302007           0   \n",
       "\n",
       "                                                                                                                       tweet  \n",
       "1355349           just looked  the other stuff  that shop  and the name  persephoneplus  not surprised you like that stuff    \n",
       "1460405                                  the cutest thing ever  two   mice running  their wheel together   wish  had  photo   \n",
       "410754   with vortex2  bumblebee stayed alive  windshield wiper through golfball size hail  succumbed  highway speeds later   \n",
       "702594                                                                                                  nice  and not  nice   \n",
       "302007                                                           stinky men are sitting beside   the jeep  this sucks  bad    "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df['tweet'].map(lambda tweet: processTweet(tweet))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['sentiment'].map({0: 0, 4: 1})\n",
    "X = df.drop(['sentiment'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "train_vector = count_vector.fit_transform(X_train['tweet'])\n",
    "test_vector = count_vector.transform(X_test['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(train_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = naive_bayes.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29717  7793]\n",
      " [ 9455 28035]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78     37510\n",
      "           1       0.78      0.75      0.76     37490\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     75000\n",
      "   macro avg       0.77      0.77      0.77     75000\n",
      "weighted avg       0.77      0.77      0.77     75000\n",
      "\n",
      "0.7700266666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW HERE STARTING RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords \n",
    "# from nltk.tokenize import word_tokenize \n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# X_train['tokens'] = X_train['tweet'].apply(word_tokenize)\n",
    "\n",
    "# X_train['tokens'] = X_train['tokens'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vocabulary_size = 5000\n",
    "\n",
    "\n",
    "# count_vector2 = TfidfVectorizer(max_features=vocabulary_size, stop_words=\"english\")\n",
    "\n",
    "# train_vector2 = count_vector2.fit_transform(X_train['tweet'])\n",
    "# test_vector2 = count_vector2.transform(X_test['tweet'])\n",
    "\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(X_train['tweet'])\n",
    "\n",
    "train_token = tokenizer.texts_to_sequences(X_train['tweet'])\n",
    "test_token = tokenizer.texts_to_sequences(X_test['tweet'])\n",
    "\n",
    "max_words = 50\n",
    "train_padded = sequence.pad_sequences(train_token, maxlen=max_words)\n",
    "test_padded = sequence.pad_sequences(test_token, maxlen=max_words)\n",
    "\n",
    "# train_padded = tokenizer.texts_to_matrix(X_train['tweet'], mode=\"count\")\n",
    "# test_padded = tokenizer.texts_to_matrix(X_test['tweet'], mode=\"count\")\n",
    "\n",
    "# y_train2= to_categorical(y_train, 2)\n",
    "# y_test2 = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1030 08:33:39.202919 140503265519360 deprecation_wrapper.py:119] From /home/blong/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1030 08:33:39.204236 140503265519360 deprecation_wrapper.py:119] From /home/blong/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1030 08:33:39.207383 140503265519360 deprecation_wrapper.py:119] From /home/blong/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 168,353\n",
      "Trainable params: 168,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Activation\n",
    "\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, input_dim=vocabulary_size))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# # model.add(Dense(256))\n",
    "# # model.add(Activation(\"relu\"))          \n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Dense(2))\n",
    "# model.add(Activation(\"softmax\"))\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1030 08:33:40.641692 140503265519360 deprecation_wrapper.py:119] From /home/blong/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1030 08:33:40.663249 140503265519360 deprecation_wrapper.py:119] From /home/blong/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1030 08:33:40.667374 140503265519360 deprecation.py:323] From /home/blong/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "loss_func = 'binary_crossentropy'\n",
    "# loss_func = 'categorical_crossentropy'\n",
    "model.compile(loss=loss_func, \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1030 08:33:43.540779 140503265519360 deprecation_wrapper.py:119] From /home/blong/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 45000 samples\n",
      "Epoch 1/3\n",
      "180000/180000 [==============================] - 133s 741us/step - loss: 0.4808 - acc: 0.7687 - val_loss: 0.4562 - val_acc: 0.7836\n",
      "Epoch 2/3\n",
      "180000/180000 [==============================] - 131s 729us/step - loss: 0.4331 - acc: 0.7967 - val_loss: 0.4505 - val_acc: 0.7879\n",
      "Epoch 3/3\n",
      "180000/180000 [==============================] - 131s 726us/step - loss: 0.4139 - acc: 0.8078 - val_loss: 0.4502 - val_acc: 0.7909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7e8d73128>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD IN A CHECKPOINTER HERE AND SHUFFLE = TRUE\n",
    "# from keras.callbacks import ModelCheckpoint  \n",
    "# checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', \n",
    "#                                save_best_only=True)\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "model.fit(train_padded, y_train, validation_split=0.2, batch_size=batch_size, epochs=num_epochs)\n",
    "# model.fit(train_vector2, y_train2, validation_split=0.2, batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7914266666666666\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_padded, y_test, verbose=0)\n",
    "# scores = model.evaluate(test_vector2, y_test2, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_pred = model.predict_classes(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30177  7333]\n",
      " [ 8310 29180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79     37510\n",
      "           1       0.80      0.78      0.79     37490\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     75000\n",
      "   macro avg       0.79      0.79      0.79     75000\n",
      "weighted avg       0.79      0.79      0.79     75000\n",
      "\n",
      "0.7914266666666666\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, rnn_pred))\n",
    "print(classification_report(y_test, rnn_pred))\n",
    "print(accuracy_score(y_test, rnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
